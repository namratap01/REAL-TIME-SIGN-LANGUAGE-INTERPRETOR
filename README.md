# REAL-TIME-SIGN-LANGUAGE-INTERPRETOR

<h3>This project is submitted by :

1. Namrata Prasad  (181210032)<br>
2. Ritika Singh    (181210042)</h3><br>
 
 --------

```
Branch     : CSE <br>
Subject    : Data Mining (CSB352) <br>
Instructor : Dr. Chandra Prakash <br>
```
We have submitted 2 notebooks:
1. Sign_Language_Recognition_Group11.ipynb

> To run this file, follow the given steps:
>
>  - Step 1 : Download the dataset from here - <a href="https://www.kaggle.com/grassknoted/asl-alphabet">ASL Alphabet Dataset</a>
>  - Step 2 : Unzip the folder and upload the asl_alphabet_test and asl_alphabet_train folders on your google drive inside the folder named 'Dataset'
>  - Step 3 : Run the code on google colab. You will be asked a key to mount your drive. Follow the link and enter the key.
>  - Step 4 : Run the rest of the code. The code will take care of creating folders. :)
  
2. GUI_Integrtion.ipynb

> To run our GUI in your system, follow the given steps:
>  
>  - Step 1 : Unzip the ASL_RECOGNITION_GUI.zip. It has all the models and configuration files required.
>  - Step 2 : Run the GUI_Integration file inside the folder on jupyter notebook.
>  - Step 3 : Make predictions :)
>  - Step 4 : (Optional) The default model selected is the vgg16 with fine tuning. If you wish to try out other models, you could uncomment the desired model name in the 4th code block under the object_detection() function, a screenshot for the same is given below
    

![alt text](https://cdn.discordapp.com/attachments/745135237167841430/836924383574097920/unknown.png)
